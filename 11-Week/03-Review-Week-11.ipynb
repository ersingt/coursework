{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Week 10 (Deep Learning/Neural Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Neural Networks + Keras \n",
    "\n",
    "\n",
    "### Differentiate between single layer and multi-layer perceptrons\n",
    "- **Single Layer's** have no hidden layer, just input features and a single activation function with an output which can be interpreted as the prediction. Just like the way most models we have talked about work.\n",
    "- **Multi Layer's** have 1 or more hidden layers where data is transformed and new interaction terms are created to be used to predict the output or feed into additional layers.\n",
    "\n",
    "### Define epoch, learning rate, activation function, hidden layer, neuron, weights & bias terms.\n",
    "- **Epoch:** When our full set of training data fully forward and back propagates through our network. \n",
    "    - Feed the data through the network.\n",
    "    - Calculate the errors.\n",
    "    - Propagate backwards to adjust network to better fit the data via found errors.\n",
    "- **Hidden Layer :** 1 or more neurons that sit in-between our input layer (original features) and our output layer (predictive function) that are responsible for transforming the data.\n",
    "- **Weights:** Values applied to features as they flow through the network to contribute to interaction.  Weights are randomly initialized and adjusted according to gradient decent on our loss function.  The weights function similar to coefficients in a linear or logistic regression in which the weights multiply the original value in order to affect how much each feature contributes to the interaction term that results from the activation function.\n",
    "- **Bias Terms:** Constant values that are added in to each neuron.  These are also adjusted the same way the weights are, however they exist on their own and do not _weight_ any other value.\n",
    "- **Activation Function:** A function on the neuron that takes in the sum of all features after their weights have been applied plus the Bias term and returns a new value that will be used as a feature in the next layer.\n",
    "- **Neuron:** Neurons are the weights, bias term and activation function.  NNs can have various hidden layers and each hidden layer can have various neurons.  Each neuron has their own unique set of weights and bias term and potentially unique activation function in order to arrive at a single value that represents some kind of combination of all the fed in features.\n",
    "- **Learning Rate:** How large the steps are that we take when moving through our loss function in order to increase/decrease weights in order to decrease total loss. (Same as gradient Descent)\n",
    "- **Batch:** Often we can not forward then back propagate our entire dataset at once so we divide it up into batches to flow through chunk by chunk\n",
    "- **Iteration :**The process of a single batch flowing forward and backward through the network.\n",
    "\n",
    "\n",
    "### Define Forward and Back Propagation.\n",
    "\n",
    "**Forward propagation** is the process of data flowing through the network in order to arrive at a predicted value.  \n",
    "**Backward Propagation** is the act of optimizing a network be working backwards through it, starting with the errors calculate and identifying the points in the network (weights or nodes) that are contributing most to the error and adjusting them accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Neural Networks & Convolutional Neural Networks\n",
    "\n",
    "\n",
    "\n",
    "### Explain how L1/L2, dropout, and early stopping regularization work and implement these methods in Keras\n",
    "\n",
    "**Regularization**\n",
    "- Incorporating either LASSO or Ridge regularization into back propagation is as simple as adding the regularization term to the loss function (ok, not very simple at all when you look at the math)\n",
    "- L1 typically isn't used in NNs.\n",
    "- L2 is much more popular and sometimes referred to as \"weight decay\". \n",
    "\n",
    "**Dropout**\n",
    "- The process of randomly removing nodes in training epochs to see how it affects the model.  A NN with densly connected layers will have the tendency to overfit so we can utilize drop out in order better understand if nodes should be removed or kept.  (Similar to how Random Forests reduce variance and overfitting.)\n",
    "- Dropouts can occur at any epoch and the models \"constant fear\" of loosing a node at any time prevents the over adjustment of a weight for an epoch.\n",
    "\n",
    "**Early Stopping**\n",
    "- Compares how much the loss function is changes and stops the algorithm once it hits the point where the loss function starts to go up.  This is done with the assumption that the first minimum that was hit it the global minimum. \n",
    "\n",
    "### Describe Gradient Descent with Momentum and Data Augmentation\n",
    "\n",
    "**Gradient Descent with Momentum**\n",
    "\n",
    "**Data Augmentation**\n",
    "- Generating more data from existing data.  With pictures this can be the result of transposing, rotating or reflecting and image to create a new version of it.  In addition SMOTE can be used to generate more similar observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify use cases of Convolutional Neural Networks.\n",
    "- Convolutional NNs consider features related to one another via proximity, this makes them great for assessing pictures because they are able to break down a picture the way humans do, by focusing one specific areas of the photo.\n",
    "\n",
    "### Understand how edge detection works in CNNs\n",
    "- An edge is identified by discontinuity in an image typically in color.  \n",
    "- When we pass our weights window over a panel of data in a picture we transform and map the image into smaller dimensions. \n",
    "- Our Window will have conflicting/balanced weights on each side of it, one side very positive and one side very negative. If there is a significant difference in color/greyscale (what we would interpret as a edge). When the window passes over it, the weights applied on each side of the window will no longer neutral out and instead result in a significant positive or negative value indicating there is a drastic difference in shading from one side of the window to another.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Edge Detection**\n",
    "\n",
    "Lets say we have a 5 by 1 image and a window size that is 2 by 1 that we're going to move across out image. _below_.\n",
    "\n",
    "It doesn't matter what value we assign to the pixels as long as different colors are represented by different values. Lets assign a value of `-1` to white and `1` to black.  Our window weights will be `10` and `-10`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAABLCAYAAADK+7ojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAAcFJREFUeJzt2zFuwkAQhtGZiI42qdPS4zNxqJwJ\ndzkGF0i1adIDQZb5zXudpRWakaVPWiT3GKMAErytPQDArQQLiCFYQAzBAmIIFhBDsIAYggXEECwg\nhmABMXbXDnT3qapOVVX7/f54OBwWH4plzPO89giLOR6Pa4/AA+Z5vowxPq6d63s+zZmmaZzP54cG\nYz3dvfYIi/GJWbbunscY07VzroRADMECYggWEEOwgBiCBcQQLCCGYAExBAuIIVhADMECYggWEEOw\ngBiCBcQQLCCGYAExBAuIIVhADMECYggWEEOwgBiCBcQQLCCGYAExBAuIIVhADMECYggWEEOwgBiC\nBcQQLCCGYAExBAuIIVhADMECYggWEEOwgBiCBcQQLCCGYAExBAuIIVhADMECYggWEEOwgBiCBcQQ\nLCCGYAExBAuIIVhADMECYggWEEOwgBi7awe6+1RVp7/Hn+7+XnakVb1X1WXtIRay5d2quze9X238\n/VXV5y2Heoxx8y9293mMMf17pCe35f22vFuV/V6FKyEQQ7CAGPcG62uRKZ7Hlvfb8m5V9nsJd/2H\nBbAmV0IghmABMQQLiCFYQAzBAmL8AqJdQE4W+ie9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1188788d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.palplot(sns.color_palette(['#FFFFFF','#FFFFFF', '#000000','#FFFFFF','#FFFFFF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([10,-10])\n",
    "\n",
    "# first frame is a white block then another white block\n",
    "f1 = np.array([-1,-1])\n",
    "# second frame is white block then a black block\n",
    "f2 = np.array([-1, 1])\n",
    "# third frame is a black block then a white block\n",
    "f3 = np.array([ 1,-1])\n",
    "f4 = np.array([-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame one has no differences in it thus is sums to zero\n",
    "sum(f1*w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame two HAS differences in it, thus its sum is far away from zero\n",
    "sum(f2*w)\n",
    "# its a negative value because its a light to dark transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame three HAS differences in it, thus its sum is far away from zero\n",
    "sum(f3*w)\n",
    "# its a positive value because its a dark to light transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frame four has no differences in it thus is sums to zero\n",
    "sum(f4*w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and describe \"padding\" and \"strided\" convolutions.\n",
    "- **Padding :** Given that the way edges flow over a picture an aspect of padding can be added.  This is essentially adding boarding cells of neutral values around a picture so that pixels that are in corners or along edges can be considered more often.\n",
    "    - In the event there is something important in the corner of an image, without having padding that corner may only be considered once.\n",
    "    - Typically we as humans gravitate our focus towards the center of an image and work outward, they further away from the center objects are in a picture the less we notice them, think about what happens in the corners of pictures.  Its typically not a place you consciously look at when looking at a picture, padding tries to combat NNs from picking up on this same habit.\n",
    "\n",
    "- **Strides:** Stride values determines how many units our window will shift as it flows through the image. \n",
    "    - If a stride is set to 1, then between each window iteration the window will move 1 unit (1 pixel)\n",
    "    - If a stride is set to 2, then the window will shift over 2 units (2 pixels).\n",
    "    \n",
    "### Understand how convolutions operate on volumes.\n",
    "- Volume in terms of a CNN are the aspect of dividing our original image up into several versions.  Typical case is dividing a color image up into three images 1 to represent the Red coloring, 1 to represent the Green coloring, and 1 to represent the Blue coloring (this is done with the RGB color spectrum)\n",
    "- Each color layer will have its own weight window applied to it, after that the results of all 3 weight windows * values will be aggregated into a single matrix.\n",
    "\n",
    "### Define pooling and implement max pooling.\n",
    "- Pooling layers allow us to compress output from the convolution layers.\n",
    "    - Max Pooling is typically the tactic used in the pooling layer.  This identifies and takes the strongest/most important info for retention.  \n",
    "    - Pooling is done independently across channels.  (Each \"node\" has its own unique pooling)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
