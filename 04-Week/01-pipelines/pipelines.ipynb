{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gqecqjR0yZ0L"
   },
   "source": [
    "# Pipelines \n",
    "*Author: Douglas Strodtman (SaMo), adjusted by Jeff Hale (DC)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lesson students will be able to:\n",
    "\n",
    "- Understand what a pipeline is\n",
    "- Use sklearn pipelines with transformers and an estimator\n",
    "\n",
    "---\n",
    "\n",
    "## Pipelines\n",
    "\n",
    "Pipelines make it easier to perform multiple preprocessing transformations and fit and transform our model with our data.\n",
    "\n",
    "Pipelines are an extremely powerful tool for your machine learning workflow. ðŸ› \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gqecqjR0yZ0L"
   },
   "source": [
    "Here we'll use the Boston data with `VarianceThreshold`, `SelectKBest`, `StandardScaler`, and `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O1pZeqqSnM7K"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold, f_regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ASLG-jUSzT5T"
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "boston = pd.read_csv('../data/boston_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect \n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break into X and y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6CO7Nchyh5H"
   },
   "source": [
    "We set up a pipeline by passing a list of tuples in the format\n",
    "```\n",
    "('string_name', ClassObject())\n",
    "```\n",
    "Note that we can name our steps beforehand (each of the methods that we're using is a sklearn class).\n",
    "```\n",
    "lr = LinearRegression()\n",
    "('linreg', lr)\n",
    "```\n",
    "\n",
    "We can include as many steps as we'd like. \n",
    "\n",
    "\n",
    "The final step has to be an **estimator**.\n",
    "Each prior step has to be a **transformer**.\n",
    "\n",
    "Look at the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7Bvgc8Oza4Y"
   },
   "outputs": [],
   "source": [
    "# create a pipeline instance with the following steps using the provided names (and arguments where provided)\n",
    "#     var_thresh: VarianceThreshold(.05)\n",
    "#     ss: StandardScaler()\n",
    "#     kbest: SelectKBest(f_regression, k=5)\n",
    "#     lr: LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                    # SelectKBest(f_regression, k = 4) \n",
    "                                                    # produces the same result as using LinearRegression(fit_intercept=True) \n",
    "                                                    # and choosing the first 4 features with the highest scores \n",
    "                                                    # https://stats.stackexchange.com/a/253255/198892\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZqtaQaLVzS6k"
   },
   "source": [
    "To use the pipeline, we just call fit on it our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "ZC9iaZdvfpkc",
    "outputId": "49e38369-f690-40d9-dd32-9af787f12b07"
   },
   "outputs": [],
   "source": [
    "# fit with our training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmwvf__Mz1iN"
   },
   "source": [
    "Then we can `score` on our train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qDY1mQcrf0j7",
    "outputId": "547099ab-8df2-4990-a307-8b40eaf698e1"
   },
   "outputs": [],
   "source": [
    "# score training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wdxro4Qiz4yO"
   },
   "source": [
    "and our test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LjfaVan_f3YD",
    "outputId": "3801e4da-f8d7-42ec-98be-b5713b0db056"
   },
   "outputs": [],
   "source": [
    "# score test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_sKTyB6z65a"
   },
   "source": [
    "Create another pipeline. Name this one `pipe`.  This time select only the 3 best features. Keep all the other steps the same. Fit it and score it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Does the performance improve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "You've seen how to use pipelines in sklearn.\n",
    "\n",
    "## Check for understanding\n",
    "\n",
    "- Why would you want to use a Pipeline?\n",
    "- What does every step in a Pipeline before the final step have to be?\n",
    "- What does the final step of a Pipeline have to be?\n",
    "\n",
    "Pipelines are a timesaving tool for your toolkit! ðŸ› "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week4-LearningObjectives.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
