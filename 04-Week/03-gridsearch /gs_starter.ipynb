{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "_By Jeff Hale_\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lesson students will be able to:\n",
    "\n",
    "- Understand what grid searching is\n",
    "- Use `GridSearchCV` class from sklearn to find optimal hyperparameters\n",
    "- Differentiate `cross_val_score` from `GridSearchCV`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch CV\n",
    "GridSearchCV is nifty sklearn class. ðŸ˜€ \n",
    "\n",
    "It performs cross validation, shuffles the data by default, and searches over a bunch of parameters.\n",
    "\n",
    "It replaces the old way of using a `for` loop with `cross_val_score`. \n",
    "\n",
    "Using GridSearchCV is the best way to optimize hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters vs parameters.\n",
    "\n",
    "Definition 1 of `parameters`: the things a function accepts. When you pass them to a function they are called `arguments`. This distinction is commonly misused.\n",
    "\n",
    "Definition 2 of `parameters`: the weights in a model. For example, the $ \\beta $ values in a linear regression equation.\n",
    "\n",
    "`hyperparameters` are the arguments you choose for a model that can have different values. You tune these to improve model performance. For example the most important hyperparameter for a KNN model is `n_neighbors` (the number of nearest neighbors to include in the model). \n",
    "\n",
    "\n",
    "### Just remember: YOU choose the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ASLG-jUSzT5T"
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "boston = pd.read_csv('../data/boston_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect \n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break into X and y\n",
    "X = boston.drop('MEDV', axis=1)\n",
    "y = boston['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpLqnj8QydqS"
   },
   "source": [
    "## GridSearch Syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SswTjsaI0CHa"
   },
   "source": [
    "`GridSearch` accepts an sklearn `estimator` object and a parameter grid.\n",
    "\n",
    "The param grid is a dictionary. The key is the name of the hyperparameter argument in sklearn.  \n",
    "\n",
    "The value is an iterable to search over (generally a list or a range-style object).\n",
    "\n",
    "What's an iterable? Something Python can iterate over. ðŸ˜€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use GridSearch with a Lasso model and different values for alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXmLken1jV9i"
   },
   "outputs": [],
   "source": [
    "# set up a param grid with the following:\n",
    "#     alpha: [.1, .5, 1, 1.5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s1pPWNNe1GwC"
   },
   "source": [
    "You can also specify the number of folds using `cv`. Default is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "15p4l187khbX"
   },
   "outputs": [],
   "source": [
    "# instantiate our gridsearch object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YUZCdrmt1OXj"
   },
   "source": [
    "We use this the same as other models, `fit`ting and `score`ing like normal (but now using the hyperparameters that gave us the best results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "mwmhzokykpVu",
    "outputId": "35d62df3-fd8c-4483-9360-0b8d531a18f4"
   },
   "outputs": [],
   "source": [
    "# fit on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WaXZrc7kkrme",
    "outputId": "8f03dd6b-8d5a-4ad8-e816-b44e1f9456c2"
   },
   "outputs": [],
   "source": [
    "# score the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "q_-3iBZnk7UC",
    "outputId": "2b368971-d6ed-41fd-8f0c-85c5a342def0"
   },
   "outputs": [],
   "source": [
    "# score the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0hFVUIL1cv2"
   },
   "source": [
    "So what are our best parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AN_WDPjUk84H",
    "outputId": "a4e22f44-1968-4a10-c0b8-290b540ac1c6"
   },
   "outputs": [],
   "source": [
    "# look at `.best_params_`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FzHKqHd41hdE"
   },
   "source": [
    "Note that we'll use our `best_estimator_` to access the model that was fit with our `best_params_`.\n",
    "\n",
    "Call `best_estimator_` to see all the values in the best-performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple scatter plot to compare our true values to our predictions to visualize our errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, gs.predict(X_test))\n",
    "plt.ylabel('Predicted')\n",
    "plt.xlabel('True')\n",
    "plt.plot([0, 50], [0, 50], color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "You've seen `GridSearchCV`\n",
    "\n",
    "## Check for understanding\n",
    "\n",
    "- Why would you want to use `GridSearchCV`?\n",
    "- What do you pass `GridSearchCV`?\n",
    "- How do you specify the parameter grid?\n",
    "- Does `GridSearchCV` randomize the data for cross validation?\n",
    "\n",
    "`GridSearchCV` is an extremely powerful tool for your toolkit! ðŸ› \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
