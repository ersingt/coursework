{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Webscraping OpenTable with Selenium: Guided Lab\n",
    "\n",
    "-\n",
    "---\n",
    "\n",
    "> *Note: this lab is intended to be instructor guided.*\n",
    "\n",
    "\n",
    "In today's codealong lab, we will build a scraper using [urlib](https://docs.python.org/3/library/urllib.request.html#module-urllib.request) and [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). We will remedy some of the pitfalls of automated scraping by using a \"headless\" browser called Selenium.\n",
    "\n",
    "You will be scraping OpenTable's DC listings. We're interested in knowing the restaurant's **name, location, price, cuisine, rating, and reviews.**\n",
    "\n",
    "OpenTable provides all of this information on this given page: [Open table listings](https://www.opentable.com/chicago-restaurant-listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inspect the elements of this page to assure we can find each of the bits of information in which we're interested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use `requests` and `BeautifulSoup` to read the contents of the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "\n",
    "url = 'https://www.opentable.com/washington-dc-restaurant-listings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the url we want to visit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use Beautiful Soup to convert the raw HTML into a soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract the name of each restaurant.\n",
    "\n",
    "Let's first find each restaurant name listed on the page we've loaded. How do we find the page location of the restaurant? \n",
    "\n",
    "> *Hint: we need to know where in the **html** the restaurant element is housed.*\n",
    "\n",
    "### 4.A See if you can find the restaurant name on the page. Keep in mind there are many restaurants loaded on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.B See any issues here?\n",
    "\n",
    "**ANSWER**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Enter Selenium - resolve the javascript issue using the driver and find the bookings.\n",
    "\n",
    "What we can do in this case is:\n",
    "1. Request that the page load\n",
    "2. Wait some amount of time\n",
    "3. Grab the source html from the page \n",
    "\n",
    "Because the page should believe I'm visiting from a live connection on a browser client, the JavaScript should render to be a part of the page source. I can then grab the page source.\n",
    "\n",
    "**Once you have the HTML with the javascript rendered, repeat the processes above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Repeat the process above, and let's grab location as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Get the price (dollar signs) for each restaurant.\n",
    "\n",
    "The price is number of dollar signs on a scale of one to four for each restaurant. We'll follow the same process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Get the name, location, price, cuisine, rating, and reviews for reach restaurant.\n",
    "\n",
    "Let's go through this together a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the name\n",
    "l_name = []\n",
    "\n",
    "# get the location\n",
    "l_loc = []\n",
    "\n",
    "# get the pricing\n",
    "l_pr = []\n",
    "\n",
    "# get the cuisine type\n",
    "l_cuisine = []\n",
    "    \n",
    "# get the rating out of 5\n",
    "l_rating = []\n",
    "    \n",
    "# get the number of reviews\n",
    "l_reviews = []\n",
    "\n",
    "# store it all in a dictionary of lists and make it into a dataframe\n",
    "info_dict = {'name': l_name,\n",
    "             'location': l_loc,\n",
    "             'price': l_pr,\n",
    "             'cuisine': l_cuisine,\n",
    "             'rating': l_rating,\n",
    "             'reviews': l_reviews,\n",
    "            }\n",
    "\n",
    "pd.DataFrame(info_dict).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Can we get all of the items we want from the page in a single `find_all`?\n",
    "\n",
    "To be most efficient, we want to only do a single loop for each entry on the page. That means we want to find what element all of other other elements (name, location, price, bookings) is housed within. Where on the page is each entry located?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataframe\n",
    "df = pd.DataFrame(columns=['name', 'location', 'price', 'cuisine','rating','reviews'])\n",
    "\n",
    "# one big for loop!\n",
    "    \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Does every single entry have each element we want?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS\n",
    "\n",
    "## 11. Putting it all together in a function.\n",
    "\n",
    "**Loop through each entry. For each entry:**\n",
    "1. Grab the relevant information we want (name, location, price, bookings). \n",
    "2. Produce a dataframe with the columns \"name\",\"location\",\"price\",\"bookings\" that contains the 100 entries we would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_grabber(soup, df):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Use selenium to loop through at least 5 pages and grab that information as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chi = pd.DataFrame(columns=['name', 'location', 'price', 'cuisine','rating','reviews'])\n",
    "url = 'https://www.opentable.com/chicago-restaurant-listings'\n",
    "driver = webdriver.Chrome(executable_path=\"./chromedriver/macos/chromedriver\")\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "for _ in range(6):\n",
    "    sleep(5)\n",
    "    soup_object = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    restaurant_grabber(soup_object, df_chi)\n",
    "    next_button = driver.find_element_by_link_text('Next')\n",
    "    next_button.click()\n",
    "\n",
    "driver.close()\n",
    "\n",
    "df_chi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chi[df_chi.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Other Neat-o Selenium Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use selenium to make clicks!\n",
    "\n",
    "url = 'https://www.opentable.com/chicago-restaurant-listings'\n",
    "driver = webdriver.Chrome(executable_path=\"./chromedriver/macos/chromedriver\")\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(2)\n",
    "price4 = driver.find_element_by_xpath('//*[@id=\"PriceBands-filter-items\"]/ul/li[3]/label')\n",
    "\n",
    "price4.click()\n",
    "sleep(5)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also type things into a search bar\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=\"./chromedriver/macos/chromedriver\") \n",
    "driver.get(\"http://www.python.org\")\n",
    "sleep(5)\n",
    "assert \"Python\" in driver.title\n",
    "elem = driver.find_element_by_name(\"q\")\n",
    "elem.clear()\n",
    "elem.send_keys(\"pycon\")\n",
    "sleep(5)\n",
    "elem.send_keys(Keys.RETURN)\n",
    "sleep(5)\n",
    "assert \"No results found.\" not in driver.page_source\n",
    "sleep(5)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "---\n",
    "\n",
    "The above example (and many others) are available in the Selenium docs: http://selenium-python.readthedocs.io/getting-started.html\n",
    "\n",
    "What is especially important is exploring functionality like locating elements: http://selenium-python.readthedocs.io/locating-elements.html#locating-elements\n",
    "\n",
    "FAQ:\n",
    "http://selenium-python.readthedocs.io/faq.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
