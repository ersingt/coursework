{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 4 Review\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "- Decision Trees are **non-parametric** models which means they only consider 1 feature at a time. They do not consider how multiple features interact simultaneously.\n",
    "\n",
    "### Understand the core concepts behind decision tree classifiers\n",
    "- By continuing to make splits we can isolate similar classes.\n",
    "- Decision Trees are a \"greedy\" model and thus they consider the optimal option at each split. They don't optimize the whole tree.   \n",
    "- Don't need to scale features because each feature is considered individually.\n",
    "- Does not care about distribution of features.\n",
    "- Interpretable.\n",
    "\n",
    "### For classification problems:\n",
    "- Gini is the most common calculation when deciding how to make a split.  We want to make splits that result in isolating the largest chunks of similar observations/classes.\n",
    "\n",
    "\n",
    "**Decision Tree Regressor**\n",
    "- Works similar to a classifier but makes splits to optimize (minimize) a loss metric such as MSE.\n",
    "- Before it makes a split, it looks at the current MSE and tries to identify the split that minimizes MSE.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris') \n",
    "### iris's species column is an object column and not a integer\n",
    "### As in, species names are list in text and the values are not converted to 0s,1s or 2s\n",
    "# Instantiate Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth = 3,min_samples_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make X and y\n",
    "X = iris.drop('species', axis = 1)\n",
    "y = iris['species']\n",
    "\n",
    "# fit model\n",
    "dtc.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(125.55000000000001, 190.26, 'X[3] <= 0.8\\ngini = 0.667\\nsamples = 150\\nvalue = [50, 50, 50]'),\n",
       " Text(83.7, 135.9, 'gini = 0.0\\nsamples = 50\\nvalue = [50, 0, 0]'),\n",
       " Text(167.4, 135.9, 'X[3] <= 1.75\\ngini = 0.5\\nsamples = 100\\nvalue = [0, 50, 50]'),\n",
       " Text(83.7, 81.53999999999999, 'X[2] <= 4.95\\ngini = 0.168\\nsamples = 54\\nvalue = [0, 49, 5]'),\n",
       " Text(41.85, 27.180000000000007, 'gini = 0.041\\nsamples = 48\\nvalue = [0, 47, 1]'),\n",
       " Text(125.55000000000001, 27.180000000000007, 'gini = 0.444\\nsamples = 6\\nvalue = [0, 2, 4]'),\n",
       " Text(251.10000000000002, 81.53999999999999, 'X[2] <= 4.85\\ngini = 0.043\\nsamples = 46\\nvalue = [0, 1, 45]'),\n",
       " Text(209.25, 27.180000000000007, 'gini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(292.95, 27.180000000000007, 'gini = 0.0\\nsamples = 43\\nvalue = [0, 0, 43]')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tree(dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging, Boosting & Other Ensemble Methods.\n",
    "\n",
    "### Bootstrapping\n",
    "\n",
    "Random sample with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "102           7.1          3.0           5.9          2.1\n",
       "92            5.8          2.6           4.0          1.2\n",
       "14            5.8          4.0           1.2          0.2\n",
       "106           4.9          2.5           4.5          1.7\n",
       "71            6.1          2.8           4.0          1.3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(5, replace=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-based ensembles\n",
    "\n",
    "There are variations for classification and regression. \n",
    "\n",
    "**Bagged Models**  \n",
    "- Bagging = Bootstrap AGGregatING.  \n",
    "- Build several models on random bootstrapped samples, then averaging the predictions of each model.\n",
    "- Parallelizable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forests**\n",
    "- Random because they use random subsets of the feature columns to build each tree.\n",
    "- The goal is to create trees that don't rely on \"overly important features\" and thus need to be able to generalize the data from other, maybe less important columns.\n",
    "- Start with a random subset of features for each tree.\n",
    "- Each split _can_ only consider an additional random subset of features.  (By default in sklearn the number of features considered at each split point is the square root of the total number of features).\n",
    "- Random forests are very powerful and tend to do well at reducing variance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ExtraTrees : _Extremely Random Trees_**\n",
    "- Extra Trees work similarly to Random forests, except they add an additional layer of randomness.\n",
    "- For each decision node, the ExtraTrees model only considers one possible split per feature/column.\n",
    "- Typically ExtraTree models are grown wider and deeper to account for the randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the differences between bagging and boosting.\n",
    "**Bagging**\n",
    "- Aggregates the results of all models simultaneously. Takes the mean of the trees for a regression problem and takes the majority vote of the trees in classification problem.\n",
    "- Bootstrap sampling makes each model unique in that it is (hopefully) exposed to data that is slightly different.\n",
    "- Model building can be parallelized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boosting**\n",
    "- Sequential model building\n",
    "- One model is built after learning from the previous.\n",
    "- Models learn from the mistakes of the models that they are built on.\n",
    "\n",
    "\n",
    "\n",
    "### Learn the pros and cons to using boosting models.\n",
    "- Boosting uses trees that are not deep. These are known as _weak learners_, \n",
    "\n",
    "**Pros**\n",
    "- Generally achieve higher performance than bagging when the hyperparameters are well tuned.\n",
    "\n",
    "**Cons**\n",
    "- Time consuming to properly tune hyperparameters.\n",
    "- Cannot be parallelized like bagging (bad scalability when there are huge amounts of data).\n",
    "- Higher risk of overfitting compared to bagging (so have to tune well) 😀.\n",
    "\n",
    "\n",
    "### AdaBoost\n",
    "- Adaboost stands for Adaptive Boosting\n",
    "\n",
    "Core principal: overweight difficult data points so that they are more likely to appear in subsequent data ponts.\n",
    "\n",
    "_Difficult data points_ refers to the data points that the model classified incorrectly (for a classification problem).\n",
    "\n",
    "- Each tree in the ensemble takes a dataset (reweighted if following a previous model) and makes a split.  Incorrect classifications are overweighted, and the process happens again.  \n",
    "\n",
    "- Predictions are aggregated in the end with more accurate trees getting higher weights and less accurate trees get less of a weight.\n",
    "    \n",
    "### Gradient Boosting\n",
    "\n",
    "- Gradient Boosting's core principal is predicting the residuals/errors of the previous model.\n",
    "- For a regression problem, think:\n",
    "    - build a linear regression model\n",
    "    - calculate the residuals\n",
    "    - build another linear regression model to predict the residuals\n",
    "    - combine the prediction of the first model with the residuals of the second model to incorporate the predicted error with the prediction to come to (hopefully) a better result.\n",
    "    - repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Recap of Trees and Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree \n",
    "Algorithm that takes best split in a feature (maximize purity for classification or minimize RMSE for regression problem). Like asking questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "Bootstrap aggregating. Bootstrap = randomized sample with replacement. Multiple trees averaged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods\n",
    "\n",
    "### Random Forest\n",
    "Bootstrap multiple trees, but only use a subset of features with each tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees - (Extremely Randomized Trees) \n",
    "\n",
    "Like random forests, but uses bagging instead of bootstrapped sampling and make random splits instead of best splits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "#### Gradient Boosting\n",
    "\n",
    "Learn from previous trees by creating new trees that predict the errors from the previous trees. Sequential. Lots of weak learner trees (not deep). \n",
    "\n",
    "#### Ada Boost\n",
    "\n",
    "Increased probability for each sample that gets misclassified of appearing in the tree built. Sequential. Bootstrapped, so sample may appear many times. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier \n",
    "\n",
    "Make your own ensemble!\n",
    "\n",
    "(Also VotingRegressor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```` \n",
    "\n",
    "vote = VotingClassifier([\n",
    "    ('ada', AdaBoostClassifier()),\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "])\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Support Vector Machines (SVMs)\n",
    "\n",
    "### Describe linear separability.\n",
    "- Can be separated by a line.\n",
    "\n",
    "### Differentiate between maximal margin classifiers, support vector classifiers, and support vector machines.\n",
    "\n",
    "**Maximal Margin SVM Classifiers**\n",
    "- Finds the best line to separate classes that maximizes the margin between the classes.\n",
    "- It wants to draw the boundary line that creates the largest \"No Man's Land/Demilitarized Zone\" that is equal on both sides. \n",
    "- If data is noisy, might not work.\n",
    "- Only exists when we can _perfectly_ separates our groups.\n",
    "\n",
    "**Soft-margin SVM Classifiers**\n",
    "- Like maximal margin SVM classifiers, but allows leniency of observations to cross the margins. Necessary because perfectly separable classes are often not possible.\n",
    "\n",
    "**Kernel SVMs**\n",
    "- Unlikely that we can find linear separability in our data, so we should consider non-linear separability. \n",
    "- With RBF kernel trick we transform our features into more dimensions where we can use a hyperplane to separate the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement SVMs in scikit-learn\n",
    "\n",
    "\n",
    "### Describe the effects of C and kernels on SVMs.\n",
    "- _C_ is a regularization parameter. Like with LogisticRegression, more C = less regularization.\n",
    "\n",
    "- C is the leniency in regards to mow many missclassifications are OK when drawing our line of separation.\n",
    "- If C is small: We get a less flexible boundary between our classes, leading to a less perfect classification of our training data.\n",
    "- If C is large: We get a more flexible boundary between our classes, leading to a more perfect classification of our training data.\n",
    "\n",
    "#### Kernels\n",
    "_Kernel Trick_ - take our data and force it into higher dimensions to find the best linear boundary between classes. \n",
    "\n",
    "The parameter `kernel` allows us to control how we force our data into higher dimensions.\n",
    "\n",
    "- **`rbf` (default): Radial basis kernel**. Radial, like radius, works particularly well with circular/spherical data. You need to specify hyperparameter gamma as well, where gamma > 0.\n",
    "- **`linear`: Linear kernel**. This gives us the support vector classifier. This works best with linearly separable data.\n",
    "- **`polynomial`: Polynomial kernel**. This can well with non-linear and non-spherical data. - Can be good for NLP.\n",
    "- **`sigmoid`: Sigmoid kernel**. This can well with non-linear and non-spherical data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Linear Models \n",
    "\n",
    "Describe generalized linear models.\n",
    "\n",
    "All GLMs will have three components:\n",
    "\n",
    "- **Linear**\n",
    "\n",
    "    - The linear component will always be the linear formula $\\beta_0 + \\beta_1X_1 + \\cdots + \\beta_pX_p$.\n",
    "    \n",
    "- **Link**\n",
    "\n",
    "    - The link function will transform the linear component into the range of interest.\n",
    "\n",
    "- **Random**\n",
    "    - The random component connects our predictions $\\hat{Y}_i$ to our observed values $Y_i$ by using a statistical distribution to model our errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "When do we use it? \n",
    "    - When we want to model something on the $(-\\infty,\\infty)$ range\n",
    "\n",
    "### Logistic Regression\n",
    "When do we use it? \n",
    "    - For predicting values between 0 and 1. \n",
    "\n",
    "### Poisson Regression \n",
    "When do we use it? \n",
    "    - When we want to model something on the $\\{0,1,2,\\ldots\\}$ range... like number of cars on through a toll road, number of objects sold or number of awards earned!\n",
    "\n",
    "### Gamma Regression \n",
    "When do we use it? \n",
    "    - When we want to model something on the $[0,\\infty)$ range... like time until some event occurs!\n",
    "\n",
    "#### Not necessary to memorize, but feel free to go back and review:\n",
    "\n",
    "- What's the link function for each of the above?\n",
    "- What's the distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Understand** the intuition behind gradient descent.\n",
    "\n",
    "Gradient Descent is how many machine learning algorithms fit models. They try to **Iteratively** solve for the absolute best parameters given certain features (our X), associated targets (our y), and a cost function (such as MSE).\n",
    "\n",
    "They try to find the minimum result of the cost function. \n",
    "\n",
    "They take steps down the curve by using the derivative to decide which way to go. \n",
    "\n",
    "Requires a learning rate (alpha). The learning rate tells you how far to move to the side. (Along the X axis if there is only one feature).\n",
    "\n",
    "For instance we use gradient descent to solve for the best coefficients when we fit a lasso regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Implement** gradient descent.\n",
    "\n",
    "- Start with a random value for beta(s), a learning rate, and a loss function.\n",
    "\n",
    "- Find the derivative using the loss function and your values for x . \n",
    "\n",
    "    - If negative, move right, if positive, move left. \n",
    "\n",
    "- How far you move to the right or left is based on the learning rate (alpha).\n",
    "    \n",
    "- Update the beta weight coefficients based on the learning rate . \n",
    "\n",
    "- Repeat the loop until stopping rate is met (not much improvement or run out iterations)!  \n",
    "    - find derivative\n",
    "    - move along the x axis in the indicated direction, as far as the learning rate tells you\n",
    "    - update beta weight coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Understand** common pitfalls associated with gradient descent.\n",
    "\n",
    "<img src=\"./assets/gdpitfal.png\" height=\"400\" width=\"600\">\n",
    "\n",
    "![](./assets/gdpitfal.png)\n",
    "\n",
    "---\n",
    "<img src=\"./assets/gdpitfall2.png\" height=\"400\" width=\"600\">\n",
    "\n",
    "- If step size is too big, convergence may not happen. You might bounce back and forth above the minimum.\n",
    "- If too small, it may take too long to converge (run out of iterations).\n",
    "- Potential to get stuck in a local minimum, if one exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Identify** solutions for common pitfalls.\n",
    "\n",
    "\n",
    "#### Solution 1\n",
    "\n",
    "Change the learning rate over time. \n",
    "    - One common method is to start large and then make it smaller. \n",
    "    - You can also draw the learning rate at each iteration from a distribution.\n",
    "\n",
    "\n",
    "#### Solution 2\n",
    "\n",
    "Try several complete runs and change the starting point of the algorithm each time. \n",
    "\n",
    "If we get nearly identical results a few times, we can be more confident that we've arrived at the global minimum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand convex vs. nonconvex loss functions \n",
    "\n",
    "#### A convex loss function has one minimum.\n",
    "\n",
    "There is not a local minimum that is different from the global minimum. \n",
    "\n",
    "Here's an example of a convex loss function.\n",
    "\n",
    "![](https://i.stack.imgur.com/w2KpJ.gif)\n",
    "\n",
    "\n",
    "Source: Avik Mohan  https://stats.stackexchange.com/a/324570/198892\n",
    "\n",
    "#### A non-convex loss function has a local minimum that is not the global minimum.\n",
    "\n",
    "Here's a non-convex loss function:\n",
    "\n",
    "![](https://i.stack.imgur.com/XrUE6.gif)\n",
    "\n",
    "It's got a hump.\n",
    "\n",
    "Source: Avik Mohan  https://stats.stackexchange.com/a/324570/198892\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the difference between local minimum and global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the image above, the valley to the left is a local minimum. It's a valley. It's not the lowest valley.\n",
    "\n",
    "The valley on the right is the lowest valley. It is the global maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
